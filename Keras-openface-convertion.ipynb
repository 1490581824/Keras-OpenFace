{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from utils import LRN2D\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contruct the model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(ZeroPadding2D(padding=(3, 3), input_shape=(3, 96, 96), data_format='channels_first'))\n",
    "model.add(Conv2D(64, (7, 7), strides=(2, 2), data_format='channels_first', name='conv1'))\n",
    "model.add(BatchNormalization(axis=1, epsilon=0.00001, name='bn1'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(ZeroPadding2D(padding=(1, 1), data_format='channels_first'))\n",
    "model.add(MaxPooling2D(pool_size=3, strides=2, data_format='channels_first'))\n",
    "model.add(Lambda(LRN2D))\n",
    "\n",
    "#8 => Inception2, torch layer6\n",
    "model.add(Conv2D(64, (1, 1), data_format='channels_first', name='conv2'))\n",
    "model.add(BatchNormalization(axis=1, epsilon=0.00001, name='bn2'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(ZeroPadding2D(padding=(1, 1), data_format='channels_first'))\n",
    "model.add(Conv2D(192, (3, 3), data_format='channels_first', name='conv3'))\n",
    "model.add(BatchNormalization(axis=1, epsilon=0.00001, name='bn3'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Lambda(LRN2D))\n",
    "model.add(ZeroPadding2D(padding=(1, 1), data_format='channels_first'))\n",
    "model.add(MaxPooling2D(pool_size=3, strides=2, data_format='channels_first'))\n",
    "\n",
    "myInput = Input(shape=(3, 96, 96))\n",
    "mid_output = model(myInput)\n",
    "\n",
    "# Inception3a\n",
    "inception_3a_3x3 = Conv2D(96, (1, 1), data_format='channels_first', name='inception_3a_3x3_conv1')(mid_output)\n",
    "inception_3a_3x3 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_3x3_bn1')(inception_3a_3x3)\n",
    "inception_3a_3x3 = Activation('relu')(inception_3a_3x3)\n",
    "inception_3a_3x3 = ZeroPadding2D(padding=(1, 1), data_format='channels_first')(inception_3a_3x3)\n",
    "inception_3a_3x3 = Conv2D(128, (3, 3), data_format='channels_first', name='inception_3a_3x3_conv2')(inception_3a_3x3)\n",
    "inception_3a_3x3 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_3x3_bn2')(inception_3a_3x3)\n",
    "inception_3a_3x3 = Activation('relu')(inception_3a_3x3)\n",
    "\n",
    "inception_3a_5x5 = Conv2D(16, (1, 1), data_format='channels_first', name='inception_3a_5x5_conv1')(mid_output)\n",
    "inception_3a_5x5 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_5x5_bn1')(inception_3a_5x5)\n",
    "inception_3a_5x5 = Activation('relu')(inception_3a_5x5)\n",
    "inception_3a_5x5 = ZeroPadding2D(padding=(2, 2), data_format='channels_first')(inception_3a_5x5)\n",
    "inception_3a_5x5 = Conv2D(32, (5, 5), data_format='channels_first', name='inception_3a_5x5_conv2')(inception_3a_5x5)\n",
    "inception_3a_5x5 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_5x5_bn2')(inception_3a_5x5)\n",
    "inception_3a_5x5 = Activation('relu')(inception_3a_5x5)\n",
    "\n",
    "inception_3a_pool = MaxPooling2D(pool_size=3, strides=2, data_format='channels_first')(mid_output)\n",
    "inception_3a_pool = Conv2D(32, (1, 1), data_format='channels_first', name='inception_3a_pool_conv')(inception_3a_pool)\n",
    "inception_3a_pool = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_pool_bn')(inception_3a_pool)\n",
    "inception_3a_pool = Activation('relu')(inception_3a_pool)\n",
    "inception_3a_pool = ZeroPadding2D(padding=((3, 4), (3, 4)), data_format='channels_first')(inception_3a_pool)\n",
    "\n",
    "inception_3a_1x1 = Conv2D(64, (1, 1), data_format='channels_first', name='inception_3a_1x1_conv')(mid_output)\n",
    "inception_3a_1x1 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_1x1_bn')(inception_3a_1x1)\n",
    "inception_3a_1x1 = Activation('relu')(inception_3a_1x1)\n",
    "\n",
    "inception_3a = concatenate([inception_3a_3x3, inception_3a_5x5, inception_3a_pool, inception_3a_1x1], axis=1)\n",
    "\n",
    "# Inception3b\n",
    "inception_3b_3x3 = Conv2D(96, (1, 1), data_format='channels_first', name='inception_3b_3x3_conv1')(inception_3a)\n",
    "inception_3b_3x3 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_3x3_bn1')(inception_3b_3x3)\n",
    "inception_3b_3x3 = Activation('relu')(inception_3b_3x3)\n",
    "inception_3b_3x3 = ZeroPadding2D(padding=(1, 1), data_format='channels_first')(inception_3b_3x3)\n",
    "inception_3b_3x3 = Conv2D(128, (3, 3), data_format='channels_first', name='inception_3b_3x3_conv2')(inception_3b_3x3)\n",
    "inception_3b_3x3 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_3x3_bn2')(inception_3b_3x3)\n",
    "inception_3b_3x3 = Activation('relu')(inception_3b_3x3)\n",
    "\n",
    "inception_3b_5x5 = Conv2D(32, (1, 1), data_format='channels_first', name='inception_3b_5x5_conv1')(inception_3a)\n",
    "inception_3b_5x5 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_5x5_bn1')(inception_3b_5x5)\n",
    "inception_3b_5x5 = Activation('relu')(inception_3b_5x5)\n",
    "inception_3b_5x5 = ZeroPadding2D(padding=(2, 2), data_format='channels_first')(inception_3b_5x5)\n",
    "inception_3b_5x5 = Conv2D(64, (5, 5), data_format='channels_first', name='inception_3b_5x5_conv2')(inception_3b_5x5)\n",
    "inception_3b_5x5 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_5x5_bn2')(inception_3b_5x5)\n",
    "inception_3b_5x5 = Activation('relu')(inception_3b_5x5)\n",
    "\n",
    "inception_3b_pool = Lambda(lambda x: x**2)(inception_3a)\n",
    "inception_3b_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3), data_format='channels_first')(inception_3b_pool)\n",
    "inception_3b_pool = Lambda(lambda x: x*9)(inception_3b_pool)\n",
    "inception_3b_pool = Lambda(lambda x: K.sqrt(x))(inception_3b_pool)\n",
    "inception_3b_pool = Conv2D(64, (1, 1), data_format='channels_first', name='inception_3b_pool_conv')(inception_3b_pool)\n",
    "inception_3b_pool = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_pool_bn')(inception_3b_pool)\n",
    "inception_3b_pool = Activation('relu')(inception_3b_pool)\n",
    "inception_3b_pool = ZeroPadding2D(padding=(4, 4), data_format='channels_first')(inception_3b_pool)\n",
    "\n",
    "inception_3b_1x1 = Conv2D(64, (1, 1), data_format='channels_first', name='inception_3b_1x1_conv')(inception_3a)\n",
    "inception_3b_1x1 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_1x1_bn')(inception_3b_1x1)\n",
    "inception_3b_1x1 = Activation('relu')(inception_3b_1x1)\n",
    "\n",
    "inception_3b = concatenate([inception_3b_3x3, inception_3b_5x5, inception_3b_pool, inception_3b_1x1], axis=1)\n",
    "\n",
    "# Inception3c\n",
    "inception_3c_3x3 = utils.conv2d_bn(inception_3b,\n",
    "                                   layer='inception_3c_3x3',\n",
    "                                   cv1_out=128,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=256,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(2, 2),\n",
    "                                   padding=(1, 1))\n",
    "\n",
    "inception_3c_5x5 = utils.conv2d_bn(inception_3b,\n",
    "                                   layer='inception_3c_5x5',\n",
    "                                   cv1_out=32,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=64,\n",
    "                                   cv2_filter=(5, 5),\n",
    "                                   cv2_strides=(2, 2),\n",
    "                                   padding=(2, 2))\n",
    "\n",
    "inception_3c_pool = MaxPooling2D(pool_size=3, strides=2, data_format='channels_first')(inception_3b)\n",
    "inception_3c_pool = ZeroPadding2D(padding=((0, 1), (0, 1)), data_format='channels_first')(inception_3c_pool)\n",
    "\n",
    "inception_3c = concatenate([inception_3c_3x3, inception_3c_5x5, inception_3c_pool], axis=1)\n",
    "\n",
    "#inception 4a\n",
    "inception_4a_3x3 = utils.conv2d_bn(inception_3c,\n",
    "                                   layer='inception_4a_3x3',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=192,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(1, 1),\n",
    "                                   padding=(1, 1))\n",
    "inception_4a_5x5 = utils.conv2d_bn(inception_3c,\n",
    "                                   layer='inception_4a_5x5',\n",
    "                                   cv1_out=32,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=64,\n",
    "                                   cv2_filter=(5, 5),\n",
    "                                   cv2_strides=(1, 1),\n",
    "                                   padding=(2, 2))\n",
    "inception_4a_pool = Lambda(lambda x: x**2)(inception_3c)\n",
    "inception_4a_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3), data_format='channels_first')(inception_4a_pool)\n",
    "inception_4a_pool = Lambda(lambda x: x*9)(inception_4a_pool)\n",
    "inception_4a_pool = Lambda(lambda x: K.sqrt(x))(inception_4a_pool)\n",
    "inception_4a_pool = utils.conv2d_bn(inception_4a_pool,\n",
    "                                   layer='inception_4a_pool',\n",
    "                                   cv1_out=128,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   padding=(2, 2))\n",
    "inception_4a_1x1 = utils.conv2d_bn(inception_3c,\n",
    "                                   layer='inception_4a_1x1',\n",
    "                                   cv1_out=256,\n",
    "                                   cv1_filter=(1, 1))\n",
    "inception_4a = concatenate([inception_4a_3x3, inception_4a_5x5, inception_4a_pool, inception_4a_1x1], axis=1)\n",
    "\n",
    "#inception4e\n",
    "inception_4e_3x3 = utils.conv2d_bn(inception_4a,\n",
    "                                   layer='inception_4e_3x3',\n",
    "                                   cv1_out=160,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=256,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(2, 2),\n",
    "                                   padding=(1, 1))\n",
    "inception_4e_5x5 = utils.conv2d_bn(inception_4a,\n",
    "                                   layer='inception_4e_5x5',\n",
    "                                   cv1_out=64,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=128,\n",
    "                                   cv2_filter=(5, 5),\n",
    "                                   cv2_strides=(2, 2),\n",
    "                                   padding=(2, 2))\n",
    "inception_4e_pool = MaxPooling2D(pool_size=3, strides=2, data_format='channels_first')(inception_4a)\n",
    "inception_4e_pool = ZeroPadding2D(padding=((0, 1), (0, 1)), data_format='channels_first')(inception_4e_pool)\n",
    "\n",
    "inception_4e = concatenate([inception_4e_3x3, inception_4e_5x5, inception_4e_pool], axis=1)\n",
    "\n",
    "#inception5a\n",
    "inception_5a_3x3 = utils.conv2d_bn(inception_4e,\n",
    "                                   layer='inception_5a_3x3',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=384,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(1, 1),\n",
    "                                   padding=(1, 1))\n",
    "inception_5a_pool = Lambda(lambda x: x**2)(inception_4e)\n",
    "inception_5a_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3), data_format='channels_first')(inception_5a_pool)\n",
    "inception_5a_pool = Lambda(lambda x: x*9)(inception_5a_pool)\n",
    "inception_5a_pool = Lambda(lambda x: K.sqrt(x))(inception_5a_pool)\n",
    "inception_5a_pool = utils.conv2d_bn(inception_5a_pool,\n",
    "                                   layer='inception_5a_pool',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   padding=(1, 1))\n",
    "inception_5a_1x1 = utils.conv2d_bn(inception_4e,\n",
    "                                   layer='inception_5a_1x1',\n",
    "                                   cv1_out=256,\n",
    "                                   cv1_filter=(1, 1))\n",
    "\n",
    "inception_5a = concatenate([inception_5a_3x3, inception_5a_pool, inception_5a_1x1], axis=1)\n",
    "\n",
    "#inception_5b\n",
    "inception_5b_3x3 = utils.conv2d_bn(inception_5a,\n",
    "                                   layer='inception_5b_3x3',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=384,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(1, 1),\n",
    "                                   padding=(1, 1))\n",
    "inception_5b_pool = MaxPooling2D(pool_size=3, strides=2, data_format='channels_first')(inception_5a)\n",
    "inception_5b_pool = utils.conv2d_bn(inception_5b_pool,\n",
    "                                   layer='inception_5b_pool',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1))\n",
    "inception_5b_pool = ZeroPadding2D(padding=(1, 1), data_format='channels_first')(inception_5b_pool)\n",
    "\n",
    "inception_5b_1x1 = utils.conv2d_bn(inception_5a,\n",
    "                                   layer='inception_5b_1x1',\n",
    "                                   cv1_out=256,\n",
    "                                   cv1_filter=(1, 1))\n",
    "inception_5b = concatenate([inception_5b_3x3, inception_5b_pool, inception_5b_1x1], axis=1)\n",
    "\n",
    "av_pool = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), data_format='channels_first')(inception_5b)\n",
    "reshape_layer = Flatten()(av_pool)\n",
    "dense_layer = Dense(128, name='dense_layer')(reshape_layer)\n",
    "norm_layer = Lambda(lambda  x: K.l2_normalize(x,axis=1))(dense_layer)\n",
    "\n",
    "\n",
    "# Final Model\n",
    "newModel = Model(inputs=[myInput], outputs=norm_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weights, Set weights and Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load weights from csv files (which was exported from Openface torch model)\n",
    "weights = utils.weights\n",
    "weights_dict = utils.load_weights()\n",
    "\n",
    "# Set layer weights of the model\n",
    "for name in weights:\n",
    "  if name in isWeightSet:\n",
    "    continue\n",
    "  if newModel.get_layer(name) != None:\n",
    "    newModel.get_layer(name).set_weights(weights_dict[name])\n",
    "    isWeightSet.append(name)\n",
    "  elif model.get_layer(name) != None:\n",
    "      model.get_layer(name).set_weights(weights_dict[name])\n",
    "      isWeightSet.append(name)\n",
    "\n",
    "# Save Keras model into HDF5 file\n",
    "newModel.save('./model/nn4.small2.v2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generate the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.06468218 -0.04559278  0.01481862 -0.05946371 -0.00458602  0.031016\n",
      "  -0.13738672  0.0864564  -0.04733388 -0.0709511  -0.0314636  -0.04022742\n",
      "  -0.04509195  0.08169178  0.09762895 -0.04431655  0.0612546  -0.1008265\n",
      "   0.16925648 -0.05656037 -0.0174047   0.02613958  0.13674961 -0.1482425\n",
      "   0.02325118  0.01902944  0.03833662 -0.08322985 -0.09595457 -0.15125816\n",
      "   0.14348972 -0.18252172  0.08168904 -0.07627811 -0.00771327  0.12772085\n",
      "  -0.00840024  0.03105799  0.00773402  0.16613343 -0.01638834  0.1560552\n",
      "  -0.1490909  -0.03831486 -0.03502201  0.12358802  0.00974787 -0.16326503\n",
      "   0.00252848 -0.03925689 -0.11491158  0.02172394  0.00648353  0.01373492\n",
      "  -0.15025629  0.01733832  0.12625058  0.00172127 -0.03638319  0.09106598\n",
      "  -0.00646602  0.04546387 -0.05698346 -0.10400727  0.12728581 -0.1647741\n",
      "   0.08533858  0.14162999  0.13371588  0.11294083  0.13427213  0.0679592\n",
      "  -0.04147187 -0.09043766  0.0246033   0.08244076 -0.15394343  0.03724954\n",
      "  -0.05324132  0.01721817 -0.24022408  0.0095697   0.03913688  0.11054858\n",
      "  -0.08685686  0.0421373   0.07118101 -0.03014113 -0.13495924 -0.20011178\n",
      "  -0.06583188  0.0312542   0.10787544  0.00198342  0.10539784 -0.07589576\n",
      "   0.0589404   0.03193255 -0.14081851  0.08117666 -0.18701154 -0.02022068\n",
      "  -0.07531302 -0.02760832  0.01689165  0.00940174  0.02343625 -0.06314481\n",
      "  -0.05043462 -0.01443668 -0.08710805 -0.1350453   0.03563076 -0.02604204\n",
      "  -0.00964355  0.05308324 -0.06493039 -0.13660248  0.00861333  0.03505076\n",
      "  -0.03063614  0.02900494 -0.09945446  0.02414764  0.07467715 -0.03232329\n",
      "  -0.02870469  0.13145274]]\n"
     ]
    }
   ],
   "source": [
    "# Read a sample image as input to test the model\n",
    "img = cv2.imread('/Users/victor_sy_wang/Developer/ML/keras-facenet/data/dlib-affine-sz/Aaron_Eckhart/Aaron_Eckhart_0001.png', 1)\n",
    "img = img[...,::-1]\n",
    "img = np.around(np.transpose(img, (2,0,1))/255.0, decimals=12)\n",
    "\n",
    "x_train = np.array([img])\n",
    "y = newModel.predict_on_batch(x_train)\n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 45 image pairs\n",
      "('batch: ', 0, ' time: ', 13.49497103691101)\n",
      "('batch: ', 1, ' time: ', 14.987068891525269)\n",
      "('batch: ', 2, ' time: ', 19.264216899871826)\n",
      "('batch: ', 3, ' time: ', 15.672331809997559)\n",
      "('batch: ', 4, ' time: ', 17.033066987991333)\n",
      "('batch: ', 5, ' time: ', 15.393961191177368)\n",
      "('batch: ', 6, ' time: ', 13.900556087493896)\n",
      "('batch: ', 7, ' time: ', 13.325394868850708)\n",
      "('batch: ', 8, ' time: ', 15.940807104110718)\n",
      "('batch: ', 9, ' time: ', 16.67252206802368)\n",
      "('batch: ', 10, ' time: ', 18.663007974624634)\n",
      "('batch: ', 11, ' time: ', 12.519654035568237)\n",
      "('batch: ', 12, ' time: ', 12.420690774917603)\n",
      "('batch: ', 13, ' time: ', 12.786065101623535)\n",
      "('batch: ', 14, ' time: ', 12.262257814407349)\n",
      "('batch: ', 15, ' time: ', 12.253498077392578)\n",
      "('batch: ', 16, ' time: ', 12.026628017425537)\n",
      "('batch: ', 17, ' time: ', 12.258782148361206)\n",
      "('batch: ', 18, ' time: ', 12.135838031768799)\n",
      "('batch: ', 19, ' time: ', 12.152045011520386)\n",
      "('batch: ', 20, ' time: ', 12.048947095870972)\n",
      "('batch: ', 21, ' time: ', 12.101548194885254)\n",
      "('batch: ', 22, ' time: ', 12.173204898834229)\n",
      "('batch: ', 23, ' time: ', 12.195671081542969)\n",
      "('batch: ', 24, ' time: ', 12.146388053894043)\n",
      "('batch: ', 25, ' time: ', 12.054917097091675)\n",
      "('batch: ', 26, ' time: ', 12.16800594329834)\n",
      "('batch: ', 27, ' time: ', 12.3230299949646)\n",
      "('batch: ', 28, ' time: ', 12.11349081993103)\n",
      "('batch: ', 29, ' time: ', 12.074453830718994)\n",
      "('batch: ', 30, ' time: ', 12.100886821746826)\n",
      "('batch: ', 31, ' time: ', 12.089756965637207)\n",
      "('batch: ', 32, ' time: ', 12.182982206344604)\n",
      "('batch: ', 33, ' time: ', 12.154558897018433)\n",
      "('batch: ', 34, ' time: ', 12.097713947296143)\n",
      "('batch: ', 35, ' time: ', 12.036495923995972)\n",
      "('batch: ', 36, ' time: ', 12.019706964492798)\n",
      "('batch: ', 37, ' time: ', 12.080356121063232)\n",
      "('batch: ', 38, ' time: ', 12.19122314453125)\n",
      "('batch: ', 39, ' time: ', 12.011656999588013)\n",
      "('batch: ', 40, ' time: ', 12.588372945785522)\n",
      "('batch: ', 41, ' time: ', 11.957659006118774)\n",
      "('batch: ', 42, ' time: ', 12.154019117355347)\n",
      "('batch: ', 43, ' time: ', 12.037590026855469)\n",
      "('batch: ', 44, ' time: ', 11.990254878997803)\n",
      "('batch: ', 45, ' time: ', 12.05930209159851)\n",
      "('batch: ', 46, ' time: ', 11.979794025421143)\n",
      "('batch: ', 47, ' time: ', 12.070133924484253)\n",
      "('batch: ', 48, ' time: ', 11.959137201309204)\n",
      "('batch: ', 49, ' time: ', 12.006223917007446)\n",
      "('batch: ', 50, ' time: ', 12.0280179977417)\n",
      "('batch: ', 51, ' time: ', 11.926735877990723)\n",
      "('batch: ', 52, ' time: ', 12.209068059921265)\n",
      "('batch: ', 53, ' time: ', 11.958615064620972)\n",
      "('batch: ', 54, ' time: ', 12.1146240234375)\n",
      "('batch: ', 55, ' time: ', 12.048353910446167)\n",
      "('batch: ', 56, ' time: ', 11.909166097640991)\n",
      "('batch: ', 57, ' time: ', 12.087668895721436)\n",
      "('batch: ', 58, ' time: ', 12.061243057250977)\n",
      "('batch: ', 59, ' time: ', 11.983948230743408)\n",
      "('batch: ', 60, ' time: ', 12.004705905914307)\n",
      "('batch: ', 61, ' time: ', 12.010567903518677)\n",
      "('batch: ', 62, ' time: ', 12.122634172439575)\n",
      "('batch: ', 63, ' time: ', 11.954758882522583)\n",
      "('batch: ', 64, ' time: ', 11.880923986434937)\n",
      "('batch: ', 65, ' time: ', 12.003550052642822)\n",
      "('batch: ', 66, ' time: ', 11.980547189712524)\n",
      "('batch: ', 67, ' time: ', 12.383386850357056)\n",
      "('batch: ', 68, ' time: ', 11.977219104766846)\n",
      "('batch: ', 69, ' time: ', 12.026066064834595)\n",
      "('batch: ', 70, ' time: ', 11.998573064804077)\n",
      "('batch: ', 71, ' time: ', 11.9237961769104)\n",
      "('batch: ', 72, ' time: ', 12.063080072402954)\n",
      "('batch: ', 73, ' time: ', 12.049098014831543)\n",
      "('batch: ', 74, ' time: ', 11.902345895767212)\n",
      "('batch: ', 75, ' time: ', 12.003915071487427)\n",
      "('batch: ', 76, ' time: ', 11.919389963150024)\n",
      "('batch: ', 77, ' time: ', 11.962755918502808)\n",
      "('batch: ', 78, ' time: ', 12.095003128051758)\n",
      "('batch: ', 79, ' time: ', 12.195001125335693)\n",
      "('batch: ', 80, ' time: ', 12.147450923919678)\n",
      "('batch: ', 81, ' time: ', 11.936463832855225)\n",
      "('batch: ', 82, ' time: ', 12.033677101135254)\n",
      "('batch: ', 83, ' time: ', 12.244007110595703)\n",
      "('batch: ', 84, ' time: ', 11.982910871505737)\n",
      "('batch: ', 85, ' time: ', 12.007007122039795)\n",
      "('batch: ', 86, ' time: ', 11.981161832809448)\n",
      "('batch: ', 87, ' time: ', 12.021687030792236)\n",
      "('batch: ', 88, ' time: ', 12.107342958450317)\n",
      "('batch: ', 89, ' time: ', 12.021857023239136)\n",
      "('batch: ', 90, ' time: ', 12.001020908355713)\n",
      "('batch: ', 91, ' time: ', 12.001677989959717)\n",
      "('batch: ', 92, ' time: ', 12.061314105987549)\n",
      "('batch: ', 93, ' time: ', 12.034312009811401)\n",
      "('batch: ', 94, ' time: ', 12.313784837722778)\n",
      "('batch: ', 95, ' time: ', 11.96467900276184)\n",
      "('batch: ', 96, ' time: ', 12.191041946411133)\n",
      "('batch: ', 97, ' time: ', 11.984467029571533)\n",
      "('batch: ', 98, ' time: ', 12.079901218414307)\n",
      "('batch: ', 99, ' time: ', 11.976831912994385)\n",
      "('batch: ', 100, ' time: ', 12.008673191070557)\n",
      "('batch: ', 101, ' time: ', 11.941250085830688)\n",
      "('batch: ', 102, ' time: ', 11.982498168945312)\n",
      "('batch: ', 103, ' time: ', 12.078994989395142)\n",
      "('batch: ', 104, ' time: ', 12.02232313156128)\n",
      "('batch: ', 105, ' time: ', 11.938585996627808)\n",
      "('batch: ', 106, ' time: ', 12.109860181808472)\n",
      "('batch: ', 107, ' time: ', 12.00570011138916)\n",
      "('batch: ', 108, ' time: ', 12.17392897605896)\n",
      "('batch: ', 109, ' time: ', 12.046940088272095)\n",
      "('batch: ', 110, ' time: ', 11.924635887145996)\n",
      "('batch: ', 111, ' time: ', 11.92563509941101)\n",
      "('batch: ', 112, ' time: ', 12.037371158599854)\n",
      "('batch: ', 113, ' time: ', 12.01089596748352)\n",
      "('batch: ', 114, ' time: ', 11.972877025604248)\n",
      "('batch: ', 115, ' time: ', 11.95726490020752)\n",
      "('batch: ', 116, ' time: ', 11.986767053604126)\n",
      "('batch: ', 117, ' time: ', 11.91977310180664)\n",
      "('batch: ', 118, ' time: ', 11.945026159286499)\n",
      "('batch: ', 119, ' time: ', 1.1950738430023193)\n",
      "Accuracy: 0.940+-0.013\n",
      "Validation rate: 0.47435+-0.04392 @ FAR=0.00134\n",
      "Area Under Curve (AUC): 0.979\n",
      "Equal Error Rate (EER): 0.062\n"
     ]
    }
   ],
   "source": [
    "# LFW TEST\n",
    "import lfw\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import facenet\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "lfw_pairs='data/pairs.txt'\n",
    "lfw_dir='data/dlib-affine-sz'\n",
    "lfw_file_ext='png'\n",
    "lfw_nrof_folds=10\n",
    "image_size=96\n",
    "batch_size=100\n",
    "\n",
    "# Read the file containing the pairs used for testing\n",
    "pairs = lfw.read_pairs(os.path.expanduser(lfw_pairs))\n",
    "\n",
    "# Get the paths for the corresponding images\n",
    "paths, actual_issame = lfw.get_paths(os.path.expanduser(lfw_dir), pairs, lfw_file_ext)\n",
    "\n",
    "embedding_size=128\n",
    "nrof_images = len(paths)\n",
    "nrof_batches = int(math.ceil(1.0*nrof_images / batch_size))\n",
    "emb_array = np.zeros((nrof_images, embedding_size))\n",
    "\n",
    "# print paths\n",
    "\n",
    "for i in range(nrof_batches):\n",
    "  start_index = i*batch_size\n",
    "  end_index = min((i+1)*batch_size, nrof_images)\n",
    "  paths_batch = paths[start_index:end_index]\n",
    "  images = facenet.load_data(paths_batch, False, False, image_size)\n",
    "  images = np.transpose(images, (0,3,1,2))\n",
    "  \n",
    "  t0 = time.time()\n",
    "  y = newModel.predict_on_batch(images)\n",
    "  emb_array[start_index:end_index,:] = y\n",
    "#   print('y', y)\n",
    "#   print('emb', emb_array[start_index:end_index,:])\n",
    "  t1 = time.time()\n",
    "  \n",
    "  print('batch: ', i, ' time: ', t1-t0)\n",
    "\n",
    "from sklearn import metrics\n",
    "from scipy.optimize import brentq\n",
    "from scipy import interpolate\n",
    "\n",
    "tpr, fpr, accuracy, val, val_std, far = lfw.evaluate(emb_array, \n",
    "                actual_issame, nrof_folds=lfw_nrof_folds)\n",
    "\n",
    "print('Accuracy: %1.3f+-%1.3f' % (np.mean(accuracy), np.std(accuracy)))\n",
    "print('Validation rate: %2.5f+-%2.5f @ FAR=%2.5f' % (val, val_std, far))\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print('Area Under Curve (AUC): %1.3f' % auc)\n",
    "eer = brentq(lambda x: 1. - x - interpolate.interp1d(fpr, tpr)(x), 0., 1.)\n",
    "print('Equal Error Rate (EER): %1.3f' % eer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
