{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D\n",
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "\n",
    "w1 = '/Users/victor_sy_wang/Developer/ML/openface/models/openface/layer1_w.csv'\n",
    "b1 = '/Users/victor_sy_wang/Developer/ML/openface/models/openface/layer1_b.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((7, 7, 3, 64), (64,), array([ 0.07432853, -0.06500489,  0.01973198, -0.03164541,  0.04986416,\n",
      "        0.04746565, -0.06268317,  0.04497291, -0.05216052, -0.06176173,\n",
      "        0.02636961, -0.03982262, -0.06870739, -0.01500778,  0.00372739,\n",
      "       -0.07971381, -0.06127921,  0.04724471, -0.03808348, -0.03344806,\n",
      "        0.07216649,  0.07477196,  0.0629585 ,  0.05848179,  0.03575065,\n",
      "       -0.03879078, -0.01604805, -0.07423716, -0.00941265,  0.0214014 ,\n",
      "       -0.02287229,  0.0663086 , -0.01010718, -0.02637136, -0.00139301,\n",
      "       -0.01988044, -0.05324499, -0.07041611, -0.06099652, -0.06074483,\n",
      "       -0.00696069,  0.07159741, -0.07825537, -0.033103  , -0.00622472,\n",
      "       -0.07154575, -0.04059464,  0.00037237, -0.00041962,  0.07437113,\n",
      "       -0.0089185 , -0.04167552, -0.01440586, -0.00870561, -0.05802949,\n",
      "        0.05733399, -0.02441243,  0.05660551,  0.04555712,  0.05215101,\n",
      "        0.0126888 ,  0.0545151 ,  0.021539  , -0.02868187]))\n"
     ]
    }
   ],
   "source": [
    "layer1_w = genfromtxt(w1, delimiter=',', dtype=None)\n",
    "layer1_w = layer1_w.reshape(64, 3, 7, 7)\n",
    "layer1_w = np.transpose(layer1_w, (2, 3, 1, 0))\n",
    "layer1_b = genfromtxt(b1, delimiter=',', dtype=None)\n",
    "# print(layer1_w.shape)\n",
    "# print(layer1_b)\n",
    "layer1 = [layer1_w, layer1_b]\n",
    "print(layer1[0].shape, layer1[1].shape, layer1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(ZeroPadding2D(padding=(3, 3), input_shape=(96, 96, 3)))\n",
    "model.add(Conv2D(64, (7, 7), strides=(2, 2)))\n",
    "\n",
    "model.layers[1].set_weights(layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((7, 7, 3, 64), array([ 0.07432853, -0.06500489,  0.01973198, -0.03164541,  0.04986416,\n",
      "        0.04746565, -0.06268317,  0.04497291, -0.05216052, -0.06176173,\n",
      "        0.02636961, -0.03982262, -0.06870739, -0.01500778,  0.00372739,\n",
      "       -0.07971381, -0.06127921,  0.04724471, -0.03808348, -0.03344806,\n",
      "        0.07216649,  0.07477196,  0.0629585 ,  0.05848179,  0.03575065,\n",
      "       -0.03879078, -0.01604805, -0.07423716, -0.00941265,  0.0214014 ,\n",
      "       -0.02287229,  0.0663086 , -0.01010718, -0.02637136, -0.00139301,\n",
      "       -0.01988044, -0.05324499, -0.07041611, -0.06099652, -0.06074483,\n",
      "       -0.00696069,  0.07159741, -0.07825537, -0.033103  , -0.00622472,\n",
      "       -0.07154575, -0.04059464,  0.00037237, -0.00041962,  0.07437113,\n",
      "       -0.0089185 , -0.04167552, -0.01440586, -0.00870561, -0.05802949,\n",
      "        0.05733399, -0.02441243,  0.05660551,  0.04555712,  0.05215101,\n",
      "        0.0126888 ,  0.0545151 ,  0.021539  , -0.02868187], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "w= model.layers[1].get_weights()\n",
    "print(w[0].shape, w[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[49 38 39]\n",
      "  [48 39 42]\n",
      "  [43 34 34]\n",
      "  ..., \n",
      "  [54 41 43]\n",
      "  [53 39 41]\n",
      "  [46 34 36]]\n",
      "\n",
      " [[40 29 34]\n",
      "  [35 24 28]\n",
      "  [39 28 32]\n",
      "  ..., \n",
      "  [47 35 39]\n",
      "  [50 38 42]\n",
      "  [53 42 46]]\n",
      "\n",
      " [[43 33 33]\n",
      "  [39 28 32]\n",
      "  [44 33 37]\n",
      "  ..., \n",
      "  [43 32 38]\n",
      "  [39 28 36]\n",
      "  [40 30 36]]\n",
      "\n",
      " ..., \n",
      " [[18 17 23]\n",
      "  [18 17 23]\n",
      "  [18 16 22]\n",
      "  ..., \n",
      "  [22 21 26]\n",
      "  [23 22 28]\n",
      "  [21 20 26]]\n",
      "\n",
      " [[19 18 24]\n",
      "  [18 17 23]\n",
      "  [21 16 23]\n",
      "  ..., \n",
      "  [21 20 25]\n",
      "  [19 18 24]\n",
      "  [22 21 27]]\n",
      "\n",
      " [[19 18 24]\n",
      "  [18 17 23]\n",
      "  [19 16 23]\n",
      "  ..., \n",
      "  [21 20 26]\n",
      "  [21 20 26]\n",
      "  [19 18 24]]]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('/Users/victor_sy_wang/Developer/ML/openface/images/examples-aligned/lennon-1.png', 1)\n",
    "img = img[...,::-1]\n",
    "img2 = np.transpose(img, (2,0,1)) \n",
    "print img.shape\n",
    "# print img2.shape\n",
    "cv2.imshow('img', img)\n",
    "# cv2.imshow('img2', img2)\n",
    "# cv2.waitKey(5000)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 96, 96, 3)\n",
      "(1, 48, 48, 64)\n",
      "(1, 48, 48)\n",
      "[[[ 178.89474487  295.9914856   341.25442505 ...,  396.10992432\n",
      "    383.29675293  267.45471191]\n",
      "  [  38.23655319   97.11819458  121.54769897 ...,  148.10423279\n",
      "    150.06465149  122.79751587]\n",
      "  [ -47.35509109  -45.11118698  -60.07111359 ...,  -38.27817154\n",
      "    -40.02341843   -7.02156115]\n",
      "  ..., \n",
      "  [ -18.17034149    1.40752602    7.63542986 ...,    8.53856945\n",
      "    -10.73673534   -2.1843276 ]\n",
      "  [  -6.98798895   15.44428349   22.24919891 ...,  -19.76063728\n",
      "    -26.02472878  -13.98241711]\n",
      "  [-109.96028137 -144.59524536 -167.74571228 ..., -205.91598511\n",
      "   -204.01652527 -134.10224915]]]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('/Users/victor_sy_wang/Developer/ML/openface/images/examples-aligned/lennon-1.png', 1)\n",
    "x_train = np.array([img])\n",
    "y = model.predict_on_batch(x_train)\n",
    "print(x_train.shape)\n",
    "print(y.shape)\n",
    "print(y[:, :, :, 1].shape)\n",
    "print(y[:, :, :, 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
